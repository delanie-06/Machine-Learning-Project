{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 515 entries, 0 to 514\n",
      "Data columns (total 17 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   restaurant   515 non-null    object \n",
      " 1   item         515 non-null    object \n",
      " 2   calories     515 non-null    int64  \n",
      " 3   cal_fat      515 non-null    int64  \n",
      " 4   total_fat    515 non-null    int64  \n",
      " 5   sat_fat      515 non-null    float64\n",
      " 6   trans_fat    515 non-null    float64\n",
      " 7   cholesterol  515 non-null    int64  \n",
      " 8   sodium       515 non-null    int64  \n",
      " 9   total_carb   515 non-null    int64  \n",
      " 10  fiber        503 non-null    float64\n",
      " 11  sugar        515 non-null    int64  \n",
      " 12  protein      514 non-null    float64\n",
      " 13  vit_a        301 non-null    float64\n",
      " 14  vit_c        305 non-null    float64\n",
      " 15  calcium      305 non-null    float64\n",
      " 16  salad        515 non-null    object \n",
      "dtypes: float64(7), int64(7), object(3)\n",
      "memory usage: 68.5+ KB\n",
      "XGBoost Mean Squared Error: 3609.094720658609\n",
      "XGBoost R-squared: 0.9354796517626857\n",
      "Best Model Mean Squared Error: 4025.975579166319\n",
      "Best Model R-squared: 0.9280270077490977\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"fastfood.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()\n",
    "\n",
    "# Check information about the dataset\n",
    "df.info()\n",
    "\n",
    "# Describe the dataset\n",
    "df.describe()\n",
    "\n",
    "# Check for missing values\n",
    "df.isna().sum()\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Clean up any newline characters in string columns\n",
    "df['restaurant'] = df['restaurant'].replace('\\n', '', regex=True)\n",
    "df['item'] = df['item'].replace('\\n', '', regex=True)\n",
    "df['total_fat'] = df['total_fat'].replace('\\n', '', regex=True)\n",
    "df['cholesterol'] = df['cholesterol'].replace('\\n', '', regex=True)\n",
    "\n",
    "# Handling missing values using SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[['fiber', 'protein']] = imputer.fit_transform(df[['fiber', 'protein']])\n",
    "\n",
    "# For other vitamin columns, you might want to use a different strategy\n",
    "vitamin_imputer = SimpleImputer(strategy='mean')\n",
    "df[['vit_a', 'vit_c', 'calcium']] = vitamin_imputer.fit_transform(df[['vit_a', 'vit_c', 'calcium']])\n",
    "\n",
    "# Remove outliers using IQR for 'calories' and 'protein'\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return df[(df[column] >= (Q1 - 1.5 * IQR)) & (df[column] <= (Q3 + 1.5 * IQR))]\n",
    "\n",
    "df = remove_outliers(df, 'calories')\n",
    "df = remove_outliers(df, 'protein')\n",
    "\n",
    "# Feature and target selection\n",
    "num_columns = ['cal_fat', 'total_fat', 'sat_fat', 'trans_fat', 'cholesterol', 'sodium', 'total_carb', 'fiber', 'sugar', 'protein', 'vit_a', 'vit_c', 'calcium']\n",
    "target_column = 'calories'\n",
    "X = df[num_columns]\n",
    "y = df[target_column]\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost model\n",
    "model_xgb = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"XGBoost Mean Squared Error:\", mse_xgb)\n",
    "print(\"XGBoost R-squared:\", r2_xgb)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(xgb.XGBRegressor(random_state=42), param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_y_pred = best_model.predict(X_test)\n",
    "\n",
    "best_mse = mean_squared_error(y_test, best_y_pred)\n",
    "best_r2 = r2_score(y_test, best_y_pred)\n",
    "\n",
    "print(\"Best Model Mean Squared Error:\", best_mse)\n",
    "print(\"Best Model R-squared:\", best_r2)\n",
    "\n",
    "# Final Prediction Example\n",
    "# Prepare inputs for prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "restaurant     0\n",
       "item           0\n",
       "calories       0\n",
       "cal_fat        0\n",
       "total_fat      0\n",
       "sat_fat        0\n",
       "trans_fat      0\n",
       "cholesterol    0\n",
       "sodium         0\n",
       "total_carb     0\n",
       "fiber          0\n",
       "sugar          0\n",
       "protein        0\n",
       "vit_a          0\n",
       "vit_c          0\n",
       "calcium        0\n",
       "salad          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another Final Prediction Output: 315.12082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhishek\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# example_input = np.array([[60, 7, 2, 0, 95, 1110, 44, 3, 11, 37, 4, 20, 20]])  # Example input\n",
    "# example_input_scaled = scaler.transform(example_input)  # Scale the input\n",
    "\n",
    "# # Make prediction\n",
    "# final_prediction = best_model.predict(example_input_scaled)\n",
    "# print(\"Final Prediction Output:\", final_prediction[0])\n",
    "\n",
    "# Another prediction example\n",
    "another_input = np.array([[50, 5, 1.5, 0, 65, 630, 35, 2, 3, 24, 4, 6, 15]])  # Another input\n",
    "another_input_scaled = scaler.transform(another_input)  # Scale the input\n",
    "\n",
    "# Make prediction\n",
    "another_final_prediction = best_model.predict(another_input_scaled)\n",
    "print(\"Another Final Prediction Output:\", another_final_prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Example input\n",
    "example_input = np.array([[60, 7, 2, 0, 95, 1110, 44, 3, 11, 37, 4, 20, 20]])\n",
    "\n",
    "# Load the scaler\n",
    "scaler = joblib.load('MinMaxScaler.pkl')\n",
    "\n",
    "# Scale the input\n",
    "example_input_scaled = scaler.transform(example_input)\n",
    "\n",
    "# Make prediction using your trained model (for example, an SVR model)\n",
    "y_pred = model.predict(example_input_scaled)\n",
    "\n",
    "print(\"Predicted output:\", y_pred[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
